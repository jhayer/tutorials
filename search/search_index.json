{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Juliette's tutorials Available tutorials Git in RStudio Virus detection: Intro High Throughput Sequencing data analysis","title":"Welcome to Juliette's tutorials"},{"location":"#welcome-to-juliettes-tutorials","text":"","title":"Welcome to Juliette's tutorials"},{"location":"#available-tutorials","text":"Git in RStudio Virus detection: Intro High Throughput Sequencing data analysis","title":"Available tutorials"},{"location":"git_rstudio/","text":"Git in RStudio Version control in Rstudio with Git and GitHub This tutorial uses some parts of Happy Git and GitHub for the useR by Jennifer Bryan. Step 1: Create a GitHub account Before you register, I would like to give you some tips. For most of the settings, joining organizations, etc. you will be able to deal with it in the future, so you do not need to think about all this now. Except your username. You might want to give that some thought. Some advices about the username: Incorporate your actual name! People like to know who they\u2019re dealing with. Also makes your username easier for people to guess or remember. Pick a username you will be comfortable revealing to your future boss. Shorter is better than longer. Make it timeless. Don\u2019t highlight your current university, employer, or place of residence. Reuse your username from other contexts, e.g., Twitter or Slack. But, of course, someone with no GitHub activity will probably be squatting on that. That being said, you can now register an account with GitHub. It\u2019s free! https://github.com Note : you do not need to use you SLU email address to register, you might want to use a personal one that you will keep using even if you move to another workplace. Step 2: Install Git on your computer For Windows users Install Git for Windows, also known as \u201cGit Bash\u201d, to get Git in addition to some other useful tools, such as the Bash shell. Yes, all those names are totally confusing, but you might encounter them elsewhere and I want you to be well-informed. We like this because Git for Windows leaves the Git executable in a conventional location, which will help you and other programs, e.g. RStudio, find it and use it. This also supports a transition to more expert use, because the \u201cGit Bash\u201d shell will be useful as you venture outside of R/RStudio. Note : Select \u201cUse Git from the Windows Command Prompt\u201d during installation. Otherwise, we believe it\u2019s OK to accept the defaults. Note : RStudio for Windows prefers for Git to be installed below C:/Program Files, for example the Git executable on my Windows system is found at C:/Program Files/Git/bin/git.exe. Unless you have specific reasons to otherwise, follow this convention. For MacOS and Linux users Check if git is already installed Maybe git is already installed? Go to the shell terminal and Enter which git to request the path to your Git executable: which git ## /usr/bin/git and git --version to see its version: git --version ## git version 2.15.1 If you are successful, that\u2019s great! You have Git already. No need to install! Move on to step 3. If, instead, you see something more like git: command not found , keep reading. Mac OS users might get an immediate offer to install command line developer tools. Yes, you should accept! Click \u201cInstall\u201d and read more below. Install Git on MacOS Please follow this link , read paragraph 7.3 and choose one of the 3 first options. Once git is installed, you can move to Step 3. Install Git on Linux Install Git via your distro\u2019s package manager. Ubuntu or Debian Linux: sudo apt-get install git Fedora or RedHat Linux: sudo yum install git A comprehensive list for various Linux and Unix package managers: https://git-scm.com/download/linux Step 3: git configuration In the shell (terminal or Git for Windows terminal), type: git config --global user.name 'Firstname Lastname' git config --global user.email 'my_email@slu.se' substituting your name and the email associated with your GitHub account. These 2 commands return nothing. You can check that Git understood what you typed by looking at the output of git config --global --list . Note : What user name should you give to Git? This does not have to be your GitHub username, although it can be. Another good option is your actual first name and last name. Your commits will be labelled with this name, so this should be informative to potential collaborators. What email should you give to Git? This must be the email associated with your GitHub account. Step 4: make a new repository on GitHub Go to https://github.com and make sure you are logged in. Click green \u201cNew repository\u201d button. Or, if you are on your own profile page, click on \u201cRepositories\u201d, then click the green \u201cNew\u201d button. Repository name: rstudio_git_test (or whatever you wish, we will delete this) Public YES Initialize this repository with a README Click big green button \u201cCreate repository.\u201d Copy the HTTPS clone URL to your clipboard via the green \u201cClone or Download\u201d button. Or copy the SSH URL if you chose to set up SSH keys. Step 5: Clone the new GitHub repository to your computer via RStudio In RStudio, start a new Project: File > New Project > Version Control > Git . In the \u201crepository URL\u201d paste the URL of your new GitHub repository. It will be something like this https://github.com/jhayer/rstudio_git_test.git Take charge of \u2013 or at least notice! \u2013 the local directory for the Project (under \"Create project as subdirectory of\" when you clone the Git repository). A common rookie mistake is to have no idea where you are saving files or what your working directory is. Pay attention. Be intentional. Personally, I would do this in ~/Documents/courses/reproducible_research/day4/ I suggest you check \u201cOpen in new session\u201d, as that\u2019s what you\u2019ll usually do in real life. Click \u201cCreate Project\u201d. This should download the README.md file that we created on GitHub in the previous step. Look in RStudio\u2019s file browser pane for the README.md file. Note : If you do you NOT see an option to get the Project from Version Control? Have a look here . Step 6: We are ready to start creating scripts and track them with version control! In the beginning we will prepare our working environment, and then we will create a Rscript for plotting data that we will modify step by step and use version control follow this modifications. Preparing our working directory: Let's get organised! Within your project folder, you will create 3 other folders (you can do it directly from RStudio): data, results, scripts Download the data file surveys_complete.csv from here: https://osf.io/9zkwm/download . Then place it in the data/ subfolder of your R project Creating the script From here, the tutorial is partly based on a R tutorial for data visualisation from Data Carpentry. You will now create a new Rscript plot_surveys.R in the scripts/ subfolder. Then add the first commands to the script: # Install the tidyverse if not already installed if (!requireNamespace(\"tidyverse\")) install.packages(\"tidyverse\") # loading library library(\"tidyverse\") # loading datafile surveys_complete <- read_csv(\"data/surveys_complete.csv\") # Assign plot to a variable surveys_plot <- ggplot(data = surveys_complete, mapping = aes(x = weight, y = hindfoot_length)) # Draw the plot surveys_plot + geom_point() Test the script. Does it seem to work? Add files and commit We will now use Git to add our new files to the staging area and commit! You can find the Git tab in the up right panel of RStudio. When you click on commit, you get a new window that will allow you to select the files and folders that you want to add to the staging area (you might want to commit everything except the folders results/ and data/ ) Note : Do not forget to add the files or folders that you do not want to track to the .gitignore file. You can edit this file and also, do not forget to add it and commit it! You are now ready for your initial commit!! Do not forget to write a commit message. Push to the remote repository Now you can push to GitHub, and then check online! Step 7: Practice and collaboration You will now add some code to your script, and then commit the changes and push to the remote repository. Let's add some color and transparency to our plot. Add this to your script: surveys_plot + geom_point(alpha = 0.1, color = \"blue\") Now, add and commit this change. Push! Note: You can review the changes by clicking on Diff. You can go back to a previous version with Revert. Collaboration You will now choose another student to pair with. One will be the owner, and one the collaborator. Owner : you will go to you GitHub account in the Settings , you will choose the tab Collaborators and there add the username of you collaborator. Collaborator : You will create a new project by cloning the owner's repository. Please pay attention and clone it in a new subfolder, so you do not erase your previous repo. You can add the name of your pair owner to the subfolder for example. Collaborator : you will now modify the script: We now want to use the colors in another way for our plot! We would like to color each species in the plot differently. We could use a vector as an input to the argument color. ggplot2 will provide a different color corresponding to different values in the vector. Add the following lines to the R script: surveys_plot + geom_point(alpha = 0.1, aes(color = species_id)) When you are happy with it, add, commit with an appropriate message and push! Both : Take a look to the Owner\u2019s repository on its GitHub website now (maybe you need to refresh your browser.) You should be able to see the new commit made by the Collaborator. Owner : Because you know that a collaborator has been working on your repository, you will Pull, to download locally the latest version that is hosted on the remote repository ( i.e. on GitHub) Basic collaborative workflow: In practice, it is good to be sure that you have an updated version of the repository you are collaborating on, so you should git pull before making our changes. The basic collaborative workflow would be: update your local repo - git pull origin master make your changes and stage them - git add commit your changes - git commit -m upload the changes to GitHub - git push origin master It is better to make many commits with smaller changes rather than of one commit with massive changes: small commits are easier to read and review. Switch roles You will now switch roles and repeat the exercise. In the script, we now want to use boxplots to visualize the distribution of weight within each species. Add this: ggplot(data = surveys_complete, mapping = aes(x = species_id, y = weight)) + geom_boxplot() Add, commit and push! Step 8: Conflicts and Merge Owner : Imagine that you forget to pull the latest version and you start adding code to your script: ggplot(data = surveys_complete, mapping = aes(x = species_id, y = weight)) + geom_boxplot(alpha = 0) + geom_jitter(alpha = 0.3, color = \"tomato\") Note : By adding points to boxplot, we can have a better idea of the number of measurements and of their distribution: Add, commit and push! Oops! There seems to be a conflict. You will need to edit and solve the conflict, i.e. choose which version you - owner - want to keep, before being able to merge. Step 9: Branches, Forks and Pull requests If you are interested in learning more about how to collaborate on GitHub, I suggest that you have a look at parts IV and V (chapters 21 to 27) of http://happygitwithr.com . You might also check some GitHub documentation Note : It might be that some commands or operations are not available in RStudio, in that case you can use your shell terminal.","title":"Git in RStudio"},{"location":"git_rstudio/#git-in-rstudio","text":"","title":"Git in RStudio"},{"location":"git_rstudio/#version-control-in-rstudio-with-git-and-github","text":"This tutorial uses some parts of Happy Git and GitHub for the useR by Jennifer Bryan.","title":"Version control in Rstudio with Git and GitHub"},{"location":"git_rstudio/#step-1-create-a-github-account","text":"Before you register, I would like to give you some tips. For most of the settings, joining organizations, etc. you will be able to deal with it in the future, so you do not need to think about all this now. Except your username. You might want to give that some thought. Some advices about the username: Incorporate your actual name! People like to know who they\u2019re dealing with. Also makes your username easier for people to guess or remember. Pick a username you will be comfortable revealing to your future boss. Shorter is better than longer. Make it timeless. Don\u2019t highlight your current university, employer, or place of residence. Reuse your username from other contexts, e.g., Twitter or Slack. But, of course, someone with no GitHub activity will probably be squatting on that. That being said, you can now register an account with GitHub. It\u2019s free! https://github.com Note : you do not need to use you SLU email address to register, you might want to use a personal one that you will keep using even if you move to another workplace.","title":"Step 1: Create a GitHub account"},{"location":"git_rstudio/#step-2-install-git-on-your-computer","text":"","title":"Step 2: Install Git on your computer"},{"location":"git_rstudio/#for-windows-users","text":"Install Git for Windows, also known as \u201cGit Bash\u201d, to get Git in addition to some other useful tools, such as the Bash shell. Yes, all those names are totally confusing, but you might encounter them elsewhere and I want you to be well-informed. We like this because Git for Windows leaves the Git executable in a conventional location, which will help you and other programs, e.g. RStudio, find it and use it. This also supports a transition to more expert use, because the \u201cGit Bash\u201d shell will be useful as you venture outside of R/RStudio. Note : Select \u201cUse Git from the Windows Command Prompt\u201d during installation. Otherwise, we believe it\u2019s OK to accept the defaults. Note : RStudio for Windows prefers for Git to be installed below C:/Program Files, for example the Git executable on my Windows system is found at C:/Program Files/Git/bin/git.exe. Unless you have specific reasons to otherwise, follow this convention.","title":"For Windows users"},{"location":"git_rstudio/#for-macos-and-linux-users","text":"","title":"For MacOS and Linux users"},{"location":"git_rstudio/#check-if-git-is-already-installed","text":"Maybe git is already installed? Go to the shell terminal and Enter which git to request the path to your Git executable: which git ## /usr/bin/git and git --version to see its version: git --version ## git version 2.15.1 If you are successful, that\u2019s great! You have Git already. No need to install! Move on to step 3. If, instead, you see something more like git: command not found , keep reading. Mac OS users might get an immediate offer to install command line developer tools. Yes, you should accept! Click \u201cInstall\u201d and read more below.","title":"Check if git is already installed"},{"location":"git_rstudio/#install-git-on-macos","text":"Please follow this link , read paragraph 7.3 and choose one of the 3 first options. Once git is installed, you can move to Step 3.","title":"Install Git on MacOS"},{"location":"git_rstudio/#install-git-on-linux","text":"Install Git via your distro\u2019s package manager. Ubuntu or Debian Linux: sudo apt-get install git Fedora or RedHat Linux: sudo yum install git A comprehensive list for various Linux and Unix package managers: https://git-scm.com/download/linux","title":"Install Git on Linux"},{"location":"git_rstudio/#step-3-git-configuration","text":"In the shell (terminal or Git for Windows terminal), type: git config --global user.name 'Firstname Lastname' git config --global user.email 'my_email@slu.se' substituting your name and the email associated with your GitHub account. These 2 commands return nothing. You can check that Git understood what you typed by looking at the output of git config --global --list . Note : What user name should you give to Git? This does not have to be your GitHub username, although it can be. Another good option is your actual first name and last name. Your commits will be labelled with this name, so this should be informative to potential collaborators. What email should you give to Git? This must be the email associated with your GitHub account.","title":"Step 3: git configuration"},{"location":"git_rstudio/#step-4-make-a-new-repository-on-github","text":"Go to https://github.com and make sure you are logged in. Click green \u201cNew repository\u201d button. Or, if you are on your own profile page, click on \u201cRepositories\u201d, then click the green \u201cNew\u201d button. Repository name: rstudio_git_test (or whatever you wish, we will delete this) Public YES Initialize this repository with a README Click big green button \u201cCreate repository.\u201d Copy the HTTPS clone URL to your clipboard via the green \u201cClone or Download\u201d button. Or copy the SSH URL if you chose to set up SSH keys.","title":"Step 4: make a new repository on GitHub"},{"location":"git_rstudio/#step-5-clone-the-new-github-repository-to-your-computer-via-rstudio","text":"In RStudio, start a new Project: File > New Project > Version Control > Git . In the \u201crepository URL\u201d paste the URL of your new GitHub repository. It will be something like this https://github.com/jhayer/rstudio_git_test.git Take charge of \u2013 or at least notice! \u2013 the local directory for the Project (under \"Create project as subdirectory of\" when you clone the Git repository). A common rookie mistake is to have no idea where you are saving files or what your working directory is. Pay attention. Be intentional. Personally, I would do this in ~/Documents/courses/reproducible_research/day4/ I suggest you check \u201cOpen in new session\u201d, as that\u2019s what you\u2019ll usually do in real life. Click \u201cCreate Project\u201d. This should download the README.md file that we created on GitHub in the previous step. Look in RStudio\u2019s file browser pane for the README.md file. Note : If you do you NOT see an option to get the Project from Version Control? Have a look here .","title":"Step 5: Clone the new GitHub repository to your computer via RStudio"},{"location":"git_rstudio/#step-6-we-are-ready-to-start-creating-scripts-and-track-them-with-version-control","text":"In the beginning we will prepare our working environment, and then we will create a Rscript for plotting data that we will modify step by step and use version control follow this modifications.","title":"Step 6: We are ready to start creating scripts and track them with version control!"},{"location":"git_rstudio/#preparing-our-working-directory","text":"Let's get organised! Within your project folder, you will create 3 other folders (you can do it directly from RStudio): data, results, scripts Download the data file surveys_complete.csv from here: https://osf.io/9zkwm/download . Then place it in the data/ subfolder of your R project","title":"Preparing our working directory:"},{"location":"git_rstudio/#creating-the-script","text":"From here, the tutorial is partly based on a R tutorial for data visualisation from Data Carpentry. You will now create a new Rscript plot_surveys.R in the scripts/ subfolder. Then add the first commands to the script: # Install the tidyverse if not already installed if (!requireNamespace(\"tidyverse\")) install.packages(\"tidyverse\") # loading library library(\"tidyverse\") # loading datafile surveys_complete <- read_csv(\"data/surveys_complete.csv\") # Assign plot to a variable surveys_plot <- ggplot(data = surveys_complete, mapping = aes(x = weight, y = hindfoot_length)) # Draw the plot surveys_plot + geom_point() Test the script. Does it seem to work?","title":"Creating the script"},{"location":"git_rstudio/#add-files-and-commit","text":"We will now use Git to add our new files to the staging area and commit! You can find the Git tab in the up right panel of RStudio. When you click on commit, you get a new window that will allow you to select the files and folders that you want to add to the staging area (you might want to commit everything except the folders results/ and data/ ) Note : Do not forget to add the files or folders that you do not want to track to the .gitignore file. You can edit this file and also, do not forget to add it and commit it! You are now ready for your initial commit!! Do not forget to write a commit message.","title":"Add files and commit"},{"location":"git_rstudio/#push-to-the-remote-repository","text":"Now you can push to GitHub, and then check online!","title":"Push to the remote repository"},{"location":"git_rstudio/#step-7-practice-and-collaboration","text":"You will now add some code to your script, and then commit the changes and push to the remote repository. Let's add some color and transparency to our plot. Add this to your script: surveys_plot + geom_point(alpha = 0.1, color = \"blue\") Now, add and commit this change. Push! Note: You can review the changes by clicking on Diff. You can go back to a previous version with Revert.","title":"Step 7: Practice and collaboration"},{"location":"git_rstudio/#collaboration","text":"You will now choose another student to pair with. One will be the owner, and one the collaborator. Owner : you will go to you GitHub account in the Settings , you will choose the tab Collaborators and there add the username of you collaborator. Collaborator : You will create a new project by cloning the owner's repository. Please pay attention and clone it in a new subfolder, so you do not erase your previous repo. You can add the name of your pair owner to the subfolder for example. Collaborator : you will now modify the script: We now want to use the colors in another way for our plot! We would like to color each species in the plot differently. We could use a vector as an input to the argument color. ggplot2 will provide a different color corresponding to different values in the vector. Add the following lines to the R script: surveys_plot + geom_point(alpha = 0.1, aes(color = species_id)) When you are happy with it, add, commit with an appropriate message and push! Both : Take a look to the Owner\u2019s repository on its GitHub website now (maybe you need to refresh your browser.) You should be able to see the new commit made by the Collaborator. Owner : Because you know that a collaborator has been working on your repository, you will Pull, to download locally the latest version that is hosted on the remote repository ( i.e. on GitHub) Basic collaborative workflow: In practice, it is good to be sure that you have an updated version of the repository you are collaborating on, so you should git pull before making our changes. The basic collaborative workflow would be: update your local repo - git pull origin master make your changes and stage them - git add commit your changes - git commit -m upload the changes to GitHub - git push origin master It is better to make many commits with smaller changes rather than of one commit with massive changes: small commits are easier to read and review.","title":"Collaboration"},{"location":"git_rstudio/#switch-roles","text":"You will now switch roles and repeat the exercise. In the script, we now want to use boxplots to visualize the distribution of weight within each species. Add this: ggplot(data = surveys_complete, mapping = aes(x = species_id, y = weight)) + geom_boxplot() Add, commit and push!","title":"Switch roles"},{"location":"git_rstudio/#step-8-conflicts-and-merge","text":"Owner : Imagine that you forget to pull the latest version and you start adding code to your script: ggplot(data = surveys_complete, mapping = aes(x = species_id, y = weight)) + geom_boxplot(alpha = 0) + geom_jitter(alpha = 0.3, color = \"tomato\") Note : By adding points to boxplot, we can have a better idea of the number of measurements and of their distribution: Add, commit and push! Oops! There seems to be a conflict. You will need to edit and solve the conflict, i.e. choose which version you - owner - want to keep, before being able to merge.","title":"Step 8: Conflicts and Merge"},{"location":"git_rstudio/#step-9-branches-forks-and-pull-requests","text":"If you are interested in learning more about how to collaborate on GitHub, I suggest that you have a look at parts IV and V (chapters 21 to 27) of http://happygitwithr.com . You might also check some GitHub documentation Note : It might be that some commands or operations are not available in RStudio, in that case you can use your shell terminal.","title":"Step 9: Branches, Forks and Pull requests"},{"location":"mib_basic_ngs/","text":"Virus detection Introduction to basic High Throughput Sequencing data analysis: a case of Virus Detection Table of content Introduction Softwares Required for this Tutorial Login to the training server and find the dataset Quality control Taxonomic classification with Kaiju De novo assembly Alignment of the contigs to a reference genome Mapping the reads on the viral contigs Introduction Astroviruses within porcine hosts show a remarkable diversity and are known to cause both mild and severe gastroenteritis. During outbreaks of suspected viral gastroenteritis in 11 production pig farms in Hungary in 2011, several samples were collected and screened by routine diagnostic approaches for common viral agents of gastroenteritis, including astroviruses. Since the conventional diagnostic assays did not yield conclusive etiological results, samples were subjected to viral metagenomics to discern putative new viral agents. Viral metagenomics aims at characterizing the virome, the complete viral genomic material of a sample. By enrichment of the virome and high-throughput sequencing the genetic material of the viruses is characterized. Twenty-one (21) intestinal samples were collected during 2011 in Hungary at nine large industrial pig production farms, which were reporting cases on diarrhoea amongst the 1-2 week piglets. Samples were collected from both piglets and weaned pigs. The specimens were initially screen at Agricultural Office Veterinary Diagnostic Directorate, Budapest. If the samples were deemed to originate from disease forms of unknown aetiology, they were sent to the OIE Collaborating Centre for the Biotechnology-based Diagnosis of Infectious Diseases in Veterinary Medicine, SLU, Uppsala, Sweden for further studying the possible aetiology by the application of metagenomics analysis. On this metagenomic dataset, we will perform: - quality control - taxonomic classification of the reads - de novo assembly of the trimmed reads - alignment of the obtained contigs to the reference genome of the detected virus of interest - mapping of all the dataset's reads back to the viral contigs to close the gaps - functional annotation of the obtained viral genome (at least a few genes) Softwares required for this tutorial The ones that we will use on line: Kaiju The ones that we will use on our server: Sickle SPAdes Abacas Bowtie2 The ones that you install on your machine: FastQC Ugene Login to the training server and find the dataset We will login to a training server called eBioKit by typing the following command in the terminal (replacing the X by the number that we give to you): ssh studentX@77.235.253.122 This server will be use for running some tools during all this tutorial. The Illumina reads files (R1 and R2) are in your home directory: 965_S11_L001_R1_001.fastq.gz 965_S11_L001_R2_001.fastq.gz Quality control FastQC To check the quality of the sequence data we will use a tool called FastQC. With this you can check things like read length distribution, quality distribution across the read length, sequencing artifacts and much more. FastQC has a graphical interface and can be downloaded and run on a Windows or Linux computer without installation. It is available here . So you can copy the data on your laptop by typing this command line from the terminal of your laptop (in your working directory): scp studentX@77.235.253.122:/Users/studentX/965_*.fastq.gz . Then run fastqc from the terminal by typing: fastqc & and you will get the Graphical User Interface (GUI) in which you can open your data files. However, FastQC is also available as a command line utility on the training server you are using. You can execute the program as follows: fastqc $read1 $read2 which will produce both a .zip archive containing all the plots, and a html document for you to look at the result in your browser. Open the html file with your favourite web browser, and try to interpret them. Pay special attention to the per base sequence quality and sequence length distribution. Explanations for the various quality modules can be found here . Also, have a look at examples of a good and a bad illumina read set for comparison. Sickle Most modern sequencing technologies produce reads that have deteriorating quality towards the 3'-end and some towards the 5'-end as well. Incorrectly called bases in both regions negatively impact assembles, mapping, and downstream bioinformatics analyses. We will trim each read individually down to the good quality part to keep the bad part from interfering with downstream applications. To do so, we will use sickle. Sickle is a tool that uses sliding windows along with quality and length thresholds to determine when quality is sufficiently low to trim the 3'-end of reads and also determines when the quality is sufficiently high enough to trim the 5'-end of reads. It will also discard reads based upon a length threshold. Sickle has two modes to work with both paired-end and single-end reads: sickle se and sickle pe. Running sickle by itself will print the help: sickle Running sickle with either the \"se\" or \"pe\" commands will give help specific to those commands. Since we have paired end reads: sickle pe Set the quality score to 30. This means the trimmer will work its way from both ends of each read, cutting away any bases with a quality score < 30. sickle pe -f input_file1.fastq -r input_file2.fastq -t sanger \\ -o trimmed_output_file1.fastq -p trimmed_output_file2.fastq \\ -s trimmed_singles_file.fastq -q 30 What did the trimming do to the per-base sequence quality, the per sequence quality scores and the sequence length distribution? Run FastQC again to find out. You copy the trimmed files produced by Sickle on your laptop and gzip them for FastQC and for the next step. On your laptop, in your working directory: scp studentX@77.235.253.122:/Users/studentX/trimmed*.fastq . gzip trimmed_file1.fastq gzip trimmed_file2.fastq Taxonomic classification with Kaiju We will run a taxonomic classification of our good quality reads at the Kaiju server Go to the WebServer tab, fill in the needed information, upload your reads files and select the database to use: NCBI nr Bacteria, Archaea, Viruses Once the analysis is done, visualize the results with Krona on the Kaiju server. Which kind of interesting virus do you find? De novo assembly In order to get longer sequences from the detected virus, and hopefully to obtain its complete genome, we will be using the SPAdes assembler to assemble our metagenomic dataset. As SPAdes is resource intensive and we are limited on time the resulting assembly is pre-processed. spades.py -o SPAdes --meta --only-assembler -k 21,33,55,77,99,127 --pe1-1 Forward_Fasta.fastq --pe1-2 Reverse_Fasta.fastq This will produce a series of outputs. The scaffolds will be in fasta format. You can find the results from the SPAdes assembly here SPAdes output is organised as follows: * contigs.fasta \u2013 resulting contigs * scaffolds.fasta \u2013 resulting scaffolds * assembly_graph.fastg \u2013 assembly graph * contigs.paths \u2013 contigs paths in the assembly graph * scaffolds.paths \u2013 scaffolds paths in the assembly graph * before_rr.fasta \u2013 contigs before repeat resolution corrected/ \u2013 files from read error correction configs/ \u2013 configuration files for read error correction corrected.yaml \u2013 internal configuration file Output files with corrected reads params.txt \u2013 information about SPAdes parameters in this run spades.log \u2013 SPAdes log dataset.info \u2013 internal configuration file input_dataset.yaml \u2013 internal YAML data set file K<##>/ \u2013 directory containing files from the run with K=<##> You should look at the contigs.fasta file avilable in the top directory of the assembly, this represents the best contigs from the assembly. You will find the SPAdes_Astro output directory within you data directory Alignment of the contigs to a reference genome ABACAS is intended to rapidly contiguate (align, order, orientate) , visualize and design primers to close gaps on shotgun assembled contigs based on a reference sequence. It uses MUMmer to find alignment positions and identify syntenies of assembly contigs against the reference. The output is then processed to generate a pseudomolecule taking overlaping contigs and gaps in to account. MUMmer's alignment generating programs, Nucmer and Promer are used followed by the 'delta-filter' utility function. Users could also run tblastx on contigs that are not used to generate the pseudomolecule. abacas -r astro_ref.fasta -q SPAdes_Astro/contigs.fasta -p nucmer -d -m You will find the reference genome to use. Inspect the resulting pseudo-molecule query_referens.fasta. Mapping the reads on the viral contigs After producing a putative pseudo-molecule with abacas orientation of contigs we proceed to re-mapp the trimmed data (from the sickle trimming) using Bowtie2. This enables us to get a rough estimate on how well our sequencing data covers the putative new genome as well as provide other useful statistics. We will use Bowtie2 for mapping the reads back to the obtained viral contigs. Bowtie2 requires a reference genome tu build an index from, we will use the newly created pseudo molecule for that. Additionally, Bowtie2 requires fastq data, of which we have two files that are trimmed. # First build an index to map towards # Usage: bowtie2-build [options]* <reference_in> <bt2_index_base> bowtie2-build -q astro_psudo.fasta astro_psudo_index # Then map the trimmed reads towards the index # Usage: bowtie2 [options]* -x <bt2-idx> {-1 <m1> -2 <m2> | -U <r>} [-S <sam>] bowtie2 --local -N 1 -x astro_psudo_index -1 data/trimmed_965_S11_L001_R1_001.fastq -2 data/trimmed_965_S11_L001_R2_001.fastq -S astro_psudo_map.sam Inspect the resulting statistics. How many reads were mapped towards the psudo-molecule? Download the .sam file and open it in UGENE. Inspect the coverage statistics. Genes prediction and functional annotation We will use GeneMark for predicting the genes from our assembled genome.","title":"Virus detection"},{"location":"mib_basic_ngs/#virus-detection","text":"","title":"Virus detection"},{"location":"mib_basic_ngs/#introduction-to-basic-high-throughput-sequencing-data-analysis-a-case-of-virus-detection","text":"","title":"Introduction to basic High Throughput Sequencing data analysis: a case of Virus Detection"},{"location":"mib_basic_ngs/#table-of-content","text":"Introduction Softwares Required for this Tutorial Login to the training server and find the dataset Quality control Taxonomic classification with Kaiju De novo assembly Alignment of the contigs to a reference genome Mapping the reads on the viral contigs","title":"Table of content"},{"location":"mib_basic_ngs/#introduction","text":"Astroviruses within porcine hosts show a remarkable diversity and are known to cause both mild and severe gastroenteritis. During outbreaks of suspected viral gastroenteritis in 11 production pig farms in Hungary in 2011, several samples were collected and screened by routine diagnostic approaches for common viral agents of gastroenteritis, including astroviruses. Since the conventional diagnostic assays did not yield conclusive etiological results, samples were subjected to viral metagenomics to discern putative new viral agents. Viral metagenomics aims at characterizing the virome, the complete viral genomic material of a sample. By enrichment of the virome and high-throughput sequencing the genetic material of the viruses is characterized. Twenty-one (21) intestinal samples were collected during 2011 in Hungary at nine large industrial pig production farms, which were reporting cases on diarrhoea amongst the 1-2 week piglets. Samples were collected from both piglets and weaned pigs. The specimens were initially screen at Agricultural Office Veterinary Diagnostic Directorate, Budapest. If the samples were deemed to originate from disease forms of unknown aetiology, they were sent to the OIE Collaborating Centre for the Biotechnology-based Diagnosis of Infectious Diseases in Veterinary Medicine, SLU, Uppsala, Sweden for further studying the possible aetiology by the application of metagenomics analysis. On this metagenomic dataset, we will perform: - quality control - taxonomic classification of the reads - de novo assembly of the trimmed reads - alignment of the obtained contigs to the reference genome of the detected virus of interest - mapping of all the dataset's reads back to the viral contigs to close the gaps - functional annotation of the obtained viral genome (at least a few genes)","title":"Introduction"},{"location":"mib_basic_ngs/#softwares-required-for-this-tutorial","text":"The ones that we will use on line: Kaiju The ones that we will use on our server: Sickle SPAdes Abacas Bowtie2 The ones that you install on your machine: FastQC Ugene","title":"Softwares required for this tutorial"},{"location":"mib_basic_ngs/#login-to-the-training-server-and-find-the-dataset","text":"We will login to a training server called eBioKit by typing the following command in the terminal (replacing the X by the number that we give to you): ssh studentX@77.235.253.122 This server will be use for running some tools during all this tutorial. The Illumina reads files (R1 and R2) are in your home directory: 965_S11_L001_R1_001.fastq.gz 965_S11_L001_R2_001.fastq.gz","title":"Login to the training server and find the dataset"},{"location":"mib_basic_ngs/#quality-control","text":"","title":"Quality control"},{"location":"mib_basic_ngs/#fastqc","text":"To check the quality of the sequence data we will use a tool called FastQC. With this you can check things like read length distribution, quality distribution across the read length, sequencing artifacts and much more. FastQC has a graphical interface and can be downloaded and run on a Windows or Linux computer without installation. It is available here . So you can copy the data on your laptop by typing this command line from the terminal of your laptop (in your working directory): scp studentX@77.235.253.122:/Users/studentX/965_*.fastq.gz . Then run fastqc from the terminal by typing: fastqc & and you will get the Graphical User Interface (GUI) in which you can open your data files. However, FastQC is also available as a command line utility on the training server you are using. You can execute the program as follows: fastqc $read1 $read2 which will produce both a .zip archive containing all the plots, and a html document for you to look at the result in your browser. Open the html file with your favourite web browser, and try to interpret them. Pay special attention to the per base sequence quality and sequence length distribution. Explanations for the various quality modules can be found here . Also, have a look at examples of a good and a bad illumina read set for comparison.","title":"FastQC"},{"location":"mib_basic_ngs/#sickle","text":"Most modern sequencing technologies produce reads that have deteriorating quality towards the 3'-end and some towards the 5'-end as well. Incorrectly called bases in both regions negatively impact assembles, mapping, and downstream bioinformatics analyses. We will trim each read individually down to the good quality part to keep the bad part from interfering with downstream applications. To do so, we will use sickle. Sickle is a tool that uses sliding windows along with quality and length thresholds to determine when quality is sufficiently low to trim the 3'-end of reads and also determines when the quality is sufficiently high enough to trim the 5'-end of reads. It will also discard reads based upon a length threshold. Sickle has two modes to work with both paired-end and single-end reads: sickle se and sickle pe. Running sickle by itself will print the help: sickle Running sickle with either the \"se\" or \"pe\" commands will give help specific to those commands. Since we have paired end reads: sickle pe Set the quality score to 30. This means the trimmer will work its way from both ends of each read, cutting away any bases with a quality score < 30. sickle pe -f input_file1.fastq -r input_file2.fastq -t sanger \\ -o trimmed_output_file1.fastq -p trimmed_output_file2.fastq \\ -s trimmed_singles_file.fastq -q 30 What did the trimming do to the per-base sequence quality, the per sequence quality scores and the sequence length distribution? Run FastQC again to find out. You copy the trimmed files produced by Sickle on your laptop and gzip them for FastQC and for the next step. On your laptop, in your working directory: scp studentX@77.235.253.122:/Users/studentX/trimmed*.fastq . gzip trimmed_file1.fastq gzip trimmed_file2.fastq","title":"Sickle"},{"location":"mib_basic_ngs/#taxonomic-classification-with-kaiju","text":"We will run a taxonomic classification of our good quality reads at the Kaiju server Go to the WebServer tab, fill in the needed information, upload your reads files and select the database to use: NCBI nr Bacteria, Archaea, Viruses Once the analysis is done, visualize the results with Krona on the Kaiju server. Which kind of interesting virus do you find?","title":"Taxonomic classification with Kaiju"},{"location":"mib_basic_ngs/#de-novo-assembly","text":"In order to get longer sequences from the detected virus, and hopefully to obtain its complete genome, we will be using the SPAdes assembler to assemble our metagenomic dataset. As SPAdes is resource intensive and we are limited on time the resulting assembly is pre-processed. spades.py -o SPAdes --meta --only-assembler -k 21,33,55,77,99,127 --pe1-1 Forward_Fasta.fastq --pe1-2 Reverse_Fasta.fastq This will produce a series of outputs. The scaffolds will be in fasta format. You can find the results from the SPAdes assembly here SPAdes output is organised as follows: * contigs.fasta \u2013 resulting contigs * scaffolds.fasta \u2013 resulting scaffolds * assembly_graph.fastg \u2013 assembly graph * contigs.paths \u2013 contigs paths in the assembly graph * scaffolds.paths \u2013 scaffolds paths in the assembly graph * before_rr.fasta \u2013 contigs before repeat resolution corrected/ \u2013 files from read error correction configs/ \u2013 configuration files for read error correction corrected.yaml \u2013 internal configuration file Output files with corrected reads params.txt \u2013 information about SPAdes parameters in this run spades.log \u2013 SPAdes log dataset.info \u2013 internal configuration file input_dataset.yaml \u2013 internal YAML data set file K<##>/ \u2013 directory containing files from the run with K=<##> You should look at the contigs.fasta file avilable in the top directory of the assembly, this represents the best contigs from the assembly. You will find the SPAdes_Astro output directory within you data directory","title":"De novo assembly"},{"location":"mib_basic_ngs/#alignment-of-the-contigs-to-a-reference-genome","text":"ABACAS is intended to rapidly contiguate (align, order, orientate) , visualize and design primers to close gaps on shotgun assembled contigs based on a reference sequence. It uses MUMmer to find alignment positions and identify syntenies of assembly contigs against the reference. The output is then processed to generate a pseudomolecule taking overlaping contigs and gaps in to account. MUMmer's alignment generating programs, Nucmer and Promer are used followed by the 'delta-filter' utility function. Users could also run tblastx on contigs that are not used to generate the pseudomolecule. abacas -r astro_ref.fasta -q SPAdes_Astro/contigs.fasta -p nucmer -d -m You will find the reference genome to use. Inspect the resulting pseudo-molecule query_referens.fasta.","title":"Alignment of the contigs to a reference genome"},{"location":"mib_basic_ngs/#mapping-the-reads-on-the-viral-contigs","text":"After producing a putative pseudo-molecule with abacas orientation of contigs we proceed to re-mapp the trimmed data (from the sickle trimming) using Bowtie2. This enables us to get a rough estimate on how well our sequencing data covers the putative new genome as well as provide other useful statistics. We will use Bowtie2 for mapping the reads back to the obtained viral contigs. Bowtie2 requires a reference genome tu build an index from, we will use the newly created pseudo molecule for that. Additionally, Bowtie2 requires fastq data, of which we have two files that are trimmed. # First build an index to map towards # Usage: bowtie2-build [options]* <reference_in> <bt2_index_base> bowtie2-build -q astro_psudo.fasta astro_psudo_index # Then map the trimmed reads towards the index # Usage: bowtie2 [options]* -x <bt2-idx> {-1 <m1> -2 <m2> | -U <r>} [-S <sam>] bowtie2 --local -N 1 -x astro_psudo_index -1 data/trimmed_965_S11_L001_R1_001.fastq -2 data/trimmed_965_S11_L001_R2_001.fastq -S astro_psudo_map.sam Inspect the resulting statistics. How many reads were mapped towards the psudo-molecule? Download the .sam file and open it in UGENE. Inspect the coverage statistics.","title":"Mapping the reads on the viral contigs"},{"location":"mib_basic_ngs/#genes-prediction-and-functional-annotation","text":"We will use GeneMark for predicting the genes from our assembled genome.","title":"Genes prediction and functional annotation"}]}